# 第一章 数据分析初探

#### 目标:

+ 什么是数据分析以及数据分析的类型；
+ 数据分析的基本流程；
+ 现实中的数据分析；
+ 数据分析中应避免的错误。



### 数据分析定义

数据分析：就是数据（Data）加分析（Analysis）。

“数据”就是数值，也就是我们通过观察、实验或计算得出的结果。数据有很多种，最简单的就是数字，数据也可以是文字、图像、声音等。数据可以用于科学研究、设计、验证等。

“分析”就是将研究对象的整体分为各个部分、方面、因素和层次，并分别加以考察的认识活动。分析的意义在于细致地寻找能够解决问题的主线，并以此解决问题。

因此，数据分析就是：用适当的统计分析方法对收集来的大量数据进行分析，提取有用信息和形成结论，对数据加以详细研究和概括总结的过程。



### 数据分析的目标

数据分析的目标为三大问题。

:one:我是谁：过去发生了什么。

对企业而言，首要任务就是要了解过去发生了什么。

以电商网站为例，企业需要了解新用户注册、用户复购、仓库备货、配送、应收等运营指标，提供这些指标来衡量公司的运营，用以说明当前业务是好还是坏，好的程度如何，坏的程度又如何。除了运营指标的监控，企业还需要了解各项业务的构成、业务的发展和变动情况。

“我是谁”的数据分析通常会以每天、每周、每月的报表形式来表现，有的企业还需要实时了解业务，如“双十一”活动。



:two:我从哪里来：归因。

“我是谁”的问题，解决了现状问题，那么“我从哪里来”就需要解决问题的归因，即为什么会这样。通过现状分析，我们对企业的当前运营情况有了基本了解，但为什么用户最近流失，应收却增加了？为何配送最近总是延迟？客户满意度为什么最近在下降？

这就是数据分析要解决的第二个问题，寻找问题的原因。



:three:我要到哪里去：预测。

“我要到哪里去”，简单来说就是告诉我们将来会发生什么。

一方面，我们通过对企业运营现状的了解来帮主企业对未来发展趋势做出预测，为制定企业运营目标及策略提供有效的参考与决策依据，以保证企业的可持续健康发展；

另一方面，我们需要实时预测客户的行为，针对客户进行精准营销，推断客户将商品加入购物车后的下一步行为。

类似的预测还有很多，例如，有的银行根据求职网站的岗位数量推断就业率等等。



### 数据分析分类

典型的数据分析分为三类：

+ 描述性分析：已经发生了什么？
+ 预测性分析：将发生什么？
+ 指导性分析：应该怎么办？



#### 描述性分析

描述性分析是传统数据分析的主要应用领域，使用的技术主要有基于数据仓库的报表、多维联机分析处理等，通过各种查询了解业务中发生了什么，寻找数据中的存在模式。例如，本月某类商品销售额是多少？



#### 预测性分析

预测性分析主要是基于大数据（实际上也可以基于传统的数据仓库和数据库），采用各种统计方法以及数据挖掘技术预测业务中各个方面将要发生什么。例如，基于过去几年的时间序列销售数据预测明年的销售额；基于聚类分析、分类分析、逻辑回归等技术预测客户信用等级；基于关联分析预测不同商品组合可能产生的销售效果。



#### 指导性分析

Prescriptive Analytics是一个比较难翻译的词，也有翻译成决策分析的。

此类分析的内在含义是它会告诉用户应该做什么以得到最优的结果。它主要指采用运筹科学的方法，即运用数学模型或智能优化算法，对企业应该采取的最优行动给出建议。例如，确定最优的商品定价以实现例如最大化。



### 典型的数据分析方法

+ 描述性统计分析：应用统计特征、统计表、统计图等方法，对资料的数量特征及其分布规律进行测定和描述。
+ 验证性统计分析：侧重于对已有的假设或模型进行验证。
+ 探索性数据分析：主动在数据之中发现新的特征或有用的隐藏信息。

#### 描述性统计分析

描述性统计分析是用来概括、表述事物整体状况以及事物间关联、类属关系的统计分析。通过统计处理可以简单地用几个统计值来表示一组数据的集中趋势、离散程度以及分布形状。

|          |       统计指标       |
| :------: | :------------------: |
| 集中趋势 | 平均数，中位数，众数 |
| 离散程度 |  极差，方差，标准差  |
| 分布形状 |      偏度，峰度      |



#### 验证性统计分析

验证性统计分析时对数据模型和研究假设的验证，参数估计、假设检验以及方差分析是验证性统计分析中常用的方法。

**参数估计**：就是用样本统计量去估计总体的参数。

**假设检验**：是对总体参数提出一个假设值，然后利用样本信息判断这一假设是否成立。

假设检验可分为：

+ 单样本假设检验；
+ 双样本的均值比较假设检验；
+ 成对样本的均值比较假设检验；

**方差分析**：是通过比较总体各种估计值的差异来检验方差的正态总体是否具有相同的均值，是检验多因素之间差异显著性的重要统计分析方法，常用的方差分析方法有：

+ 单因子方差分析；
+ 双因子方差分析；



#### 探索性数据分析

探索性数据分析（Exploratory Data Analysis，EDA）是指对已有数据在尽量少的先验假设下通过作图、制表、方程拟合、计算特征量等手段探索数据的结构和规律的一种数据分析方法。

传统的统计分析方法常常先假设数据符合一种统计模型，然后依据数据样本来估计模型的一些参数及统计量，以此了解数据的特征，但实际中往往有很多人数据并不符合假设的统计模型分布，导致数据分析结果不理想。

探索性数据分析则是一种更加贴合实际情况的分析方法，它强调让数据自身“说话”，通过探索性数据分析可以真实、直接地观察到数据的结构和特征。

探索性数据分析出现之后，数据分析的过程就被分为两个阶段：探索阶段和验证阶段。

+ 探索阶段侧重于发现数据中包含的模式或模型。
+ 验证阶段侧重于评估所发现的模式或模型，很多机器学习算法（分为训练和测试）都遵循这种思想。



### 数据分析的基本流程

一个完整的数据分析项目可以分为5步：问题定义，收集数据，数据处理，分析数据，结果解读与应用



#### 问题定义

企业或组织中的数据分析必须从正确的问题开始，而该问题必须清晰、简洁，并且要可度量。

我们的目标是通过提出问题来帮主寻找新的解决方案，或者说解决特定问题。

例子：

+ 某移动应用的新用户注册率趋势如何？
+ 经常购买电商网站某品类的是哪类人群？
+ 如何提高企业的销售额？

问题的定义通常需要分析人员对业务有深入了解。例如，要提高企业销售，那么需要理解企业盈利模式是什么。



#### 收集数据

有了具体的问题之后，就需要准备获取相关的数据了。首先要明确问题对应的数据是什么，这些数据如何定义，如何度量。之后就需要考虑哪些数据是已经存在的，哪些数据需要通过对现有数据进行加工来获得，哪些数据还没有。

典型的数据获取方法有以下几种：

1. 企业数据库/数据仓库。大多数公司的销售、用户数据都可以直接从企业数据库获取。
2. 外部公开数据集。一些科研机构、企业、政府会开放一些数据
3. 爬虫
4. 实验

> 我们有时并不能够获得所有需要的数据，不过这并不重要，因为我们的目标是通过有限的可获得的数据，提取更多有用的信息。





#### 数据处理

数据处理时指对采集到的数据进行加工整理，形成适合数据分析的样式，保证数据的一致性和有效性。

数据处理的基本目的是从大量的、可能杂乱无章的、难以理解的数据中抽取并推导出对解决问题有价值、有意义的数据。

数据处理主要包括数据清洗、数据转化、数据抽取、数据合并、数据计算等处理方法。

数据预处理有多种方法：数据清理、数据集成、数据变换、数据归约等。

如空气质量数据为例，很可能其中有很多天的数据由于设备的原因是没有监测到的，有一些数据是记录重复的，还有一些数据是设备鼓掌时监测无效的。那么需要用相应的方法去处理，如残缺数据，是直接去掉这条数据，还是用邻近的值去不全，这些都是需要考虑的问题。





#### 数据分析

进入数据分析阶段，需要了解不同方法适用的场景和问题。分析时切忌滥用和误用统计分析方法。

滥用和误用统计分析方法主要是由于对方法能解决哪类问题、方法适用的前提、方法对数据的要求等不清造成的。



#### 结果解读与应用

数据分析的结果需要以报告的形式展现，数据分析师如何把数据观点展示出来则至关重要。

首先，深入浅出的数据报告、言简意赅的数据结论将更有利于业务理解和接受。其次，在理解业务数据的基础上，推动业务落地实现数据建议。通常，从业务最重要、最紧急、最能产生效果的环节开始是个好方法，与此同时需要考虑到业务落地的客观环境，即好的数据结论需要具备客观落地条件。最后，需要明确的是一个数据项目工作是循序渐进的过程，无论是数据分析项目还是数据产品项目，都需要数据分析师具备计划、领导、组织、控制的项目工作能力。



### 硝烟中的数据分析

数据分析源于具体的商业问题、商业需求、唯有将其放到实际的场景才能更好地理解数据，应用数据来创造价值。



#### 数据分析的产生

现实中的数据分析总是带着紧迫性。

+ 客户支持团队负责人发现最近客户问题响应时间严重滞后，需要知道这是什么原因导致的。
+ 某家互联网公司发现最近新用户注册率下降，公司领导想知道这是什么原因导致的。

> 无论是什么问题，找到原因并解决它是当务之急。



#### 验证问题

开始任何数据分析之前，我们都需要快速验证前面定义的问题。为了验证问题，通常会提出更多问题。例如，思考这个问题可能导致更验证的问题吗？注册率的下降是否是网站故障导致？

另外，我们需要思考这个问题是否只是一个特例。例如，是否是报告错误？其他相关指标同样下降吗？

> 这个快速的初步评估回答了这两个问题：这实际上是一个问题吗？如果是的话，这里的核心问题是什么？



#### 寻找原因

1. 寻找任何快速解决问题的可能性

   我们的目标总是尽可能用最小代价获取最大回报。因此，尽可能预先思考是否有明显的可能原因或问题的答案是开始数据分析的第一步。

2. 询问其他团队

   这个问题会影响或涉及其他团队吗？如果是，其他团队是否对可能的原因有了解？即使问题与其他团队之间没有明显的联系，也值得快速询问。

3. 对可能的原因进行假设

   假设：一个尚未得到正视的有根据的猜测。我们可以将其视为测试的问题的可能解释。
   
   1. 客户支持问题的假设：问题响应时间因何增加。
      + 大量与服务相关的问题，而与产品相关的问题单相比，服务单响应时间更长
      + 只是某一个呼叫中心的问题
   2. 营销问题的假设：注册减少的原因。
      + 某些地区的公众假期
      + 最近对营销网站（或网站中断）的更改。
   3. 电子商务问题的假设：平均购物车弃购率为何增加。
      + 季节性原因（如假期、学校休息等）
      + 结束促销活动，导致更多人放弃购物车。

> 在分析数据之前，假设问题的多个可能原因非常重要。有时在对数据进行探索时，我们还可能会产生一个新的假设，之后需要测试该假设。

​	一个好的假设需要满足以下几点：

+ 它涉及一个自变量和一个因变量；
+ 它是可测试的；
+ 它是可证伪的。

自变量是原因（可以改变或控制），因变量是效果（可测试结果）。可证伪意味着假设可被证明是错误的。



#### 数据怎么说

通常人们通过假设并观察与假设进行比较来发现真相。前面的假设探索了几个可能的原因，现在就是要看数据是怎么说的。



1. 确定并分割相关数据

   根据之前的假设，判断需要查看哪些数据，哪些指标可以帮主证明或推翻的可能的原因。例如，按国家、地区、渠道或网络会话持续时间来细分注册用户。

2. 探索数据

   有经验的数据分析人员肯定知道什么情况下指标是“正常”的；基于这些知识并运用常识，会注意到什么；数据的任何方面是否出现异常。例如，针对安卓手机哟过后注册量下降了20%这一问题，如果尚未为“正常”建立基线，就需要使用历史数据作为起点，如果将本月的注册与去年同月的注册进行比较，或者看看过去12个月的注册趋势。

3. 评估异常或趋势的影响

   完整性检查，以查看发现的趋势、异常是否足以解释潜在问题。解决日常业务问题意味着我们正在寻找数据中的异常或趋势，这些异常或趋势不仅具有统计意义，而且具有实际意义。



### 数据分析中应该避免的典型问题

数据并不总是有价值的，在数据分析中需要牢记数据有时会对我们有用！下面讨论一些常见的数据谬论。

#### 单方论证

数据分析中，我们有时会陷入**单方论证陷阱（Cherry Picking）**，仅选择支持自己观点的数据，同时丢弃不支持自己观点的部分。例如，我们可能会注意到产品某个新功能相关的支持问题响应时间增加了。如果只是着眼于此，可能会得出结论，响应时间增加是新产品功能导致。但如果查看过去两个月的所有客户支持问题，可能会看到整体响应时间增加，是因为问题数量增加了。



#### 错误因果关系

我们经常会因为两个事件同时发生，就认为二者相关，这可能会导致**错误因果关系（False Causality）**。有时似乎相关的模式可能与第三个独立因子相关，而不是彼此相关。然而更好的办法是，收集更多的数据并查看可能的第三方原因。例如，我们发现放弃在线购物车的潜在客户往往具有较低的总购物价值。然而当我们深入挖掘时，可能会发现实际是由于运费的原因导致购物车弃购率上升，因为免费送货仅适用于超过特定金额的订单。



#### 幸存者偏差

**幸存者偏差（Survivorship Bias）**是一种常见的逻辑谬误（而不是“偏差”），指的是只能看到经过某种筛选而产生的结果，而没有意识到筛选的过程，因此忽略了被筛选掉的关键信息。即从不完整的数据集中得出结论，因为这些数据也仅仅是碰巧符合了一些选择标准。分析数据时，一个很重要的步骤是问一下自己有什么缺失的数据。有时可能没办法掌握数据的整体情况就是因为它们只反映了一部分。例如，在第二次世界大战中，英美空军为了加强战斗机的保护措施，对参战飞机中弹区域进行了详细统计，结果显示机翼部位中弹最密集，而机舱部位中弹最少。于是军方决定对飞机机翼进行加固，但一名统计学家站出来发对。他表示真正需要加固的是机舱，因为机舱中弹的飞机大概率无法返航，才导致了这样的统计结果。最终均方采纳了他的建议，战斗机坠毁率果然降低。这就是所谓的幸存者偏差，也称为“死人不会说话”效应，幸存者的经验往往误导了我们的判断。



#### 采样偏差

由于我们并不总是能获得全部数据，那么数据能代表总体样本就变得至关重要。





