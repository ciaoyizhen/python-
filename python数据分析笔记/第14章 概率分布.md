# 第十四章 概率分布

数据分析中可能使用的许多统计工具和技术都基于概率。所谓概率就是事件发生的可能性，其取值范围为从0（事件从未发生）到1（事件总是发生）。而分析数据时，通常会将数据集中的变量作为随机变量，即变量的值无法预先确定，仅以一定的可能性（概率）取值的量。概率分布则描述了随机变量是如何分布的，它告诉我们随机变量最有可能的值和不太可能的值。而在统计学中，存在一系列具有不同形状的精确定义的概率分布，数据分析时经常用它们来模拟不同类型的随机事件。

## 随机数

略



## 常见的概率分布

### scipy的常见命令：

```python
from scipy import stats

"""
stats.distribution.rvs()  # 生成指定分布的随机数
stats.distribution.cdf()  # 累计概率分布函数,给定x返回概率
stats.distribution.ppf()  # 与cdf相反,给定概率返回x
stats.distribution.pdf()  # 给定x值返回其概率密度
"""
```



### 均匀分布

```python
# 模拟100000个符合区间[0, 10]的均匀分布
uniform_data = stats.uniform.rvs(size=100000, loc=0, scale=10)

# 获取概率密度
pd.DataFrame(uniform_data).plot(kind='density', figsize=(6, 3), xlim=(-1, 11), fontsize=14, legend=None)

stats.uniform.cdf(x=2.5, loc=0, scale=10)  # 给定均匀分布U(0, 10), 求P(X<=2.5)

stats.uniform.ppf(x=0.4, loc=0, scale=10)  # 给定均匀分布U(0, 10), 给定P(X<=x)=0.4,求x

for x in range(-1, 12, 3):
    print(f'{x}处的概率密度(高度)为:{stats.uniform.pdf(x=x, loc=0, scale=10)}')  # 只有0-10内才有概率
```



### 正态分布

```python
prob_under_minus1 = stats.norm.cdf(x=-1, loc=0, scale=1)  # 获取P(x<=-1)
prob_over_1 = 1 - stats.norm.cdf(x=1, loc=0, scale=1)  # 获取P(x>=1)
between_prob = 1 - (prob_under_minus1+prob_over_1)  # 获取P(-1<=X<=1), 也就是P(-σ<=x<=σ)
print(between_prob)  # 这个结果为0.68

```

绘图

```python
import matplotlib.pyplot as plt
import seaborn as sns

colors = sns.color_palette()

plt.figure(figsize=(10, 6))
plt.fill_between(x=np.arange(-4, -1, 0.01), y1=stats.norm.pdf(np.arange(-4, -1, 0.01)), color=colors[0])  # 区域填充图
plt.fill_between(x=np.arange(-1, 1, 0.01), y1=stats.norm.pdf(np.arange(-1, 1, 0.01)), color=colors[1])
plt.fill_between(x=np.arange(1, 4, 0.01), y1=stats.norm.pdf(np.arange(1, 4, 0.01)), color=colors[0])
plt.show()
```



### 二项分布

```python
fair_coin_flips = stats.binom.rvs(n=10, p=0.5, size=100000)
pd.crosstab(index='count', columns=fair_coin_flips)  # 将n转为列名,值为次数
pd.DataFrame(fair_coin_flips).hist(range=(-0.5, 10.5), bins=11)  # 绘制图形

# 若想知道抛硬币正面出现5个或更少怎么计算
stats.binom.cdf(k=5, n=10, p=0.5)  # P(x<=5)
stats.binom.pmf(k=5, n=10, p=0.5)  # P(x=5)  # 连续分布使用pdf, 离散分布是pmf
```

#### 泊松分布

泊松分布用于描述单位时间内随机事件发生次数的概率分布，它也是离散分布。

例如等公交车，假设这些公交车的到来是独立且随机的（当然这不是现实），前后车之间没有关系，那么在1小时中到来的公交车数量就符合泊松分布。日常生活中大量时间是有固定频率的。如医院平均每小时出生10个婴儿等。

它们的特点是可以预估这些事件的总数，但是没法知道具体的发生时间。

```python
# 模拟一个时间单元发生一次的泊松分布
arrival_rate_1 = stats.poisson.rvs(size=10000, mu=1)
pd.DataFrame(arrival_rate_1).hist(range=(-0.5, max(arrival_rate_1)+0.5), bins=max(arrival_rate_1)+1, figsize=(10, 6))  # 画图
```

举一个生活的中的例子。

假设某家销售零食的网店平均每周卖出30件坚果零食，请问该网店的最佳库存量应该是多少？对于此问题，假定不存在季节以及促销因素，那么可以近似认为该问题满足以下三个条件：顾客购买坚果是小概率事件；购买坚果的顾客之间是独立的，即不会互相依赖或影响；顾客购买坚果的概率是稳定的。

在统计学上，如果某类事件满足上述三个条件，就称它服从泊松分布。

```python
rv = stats.poisson(mu=30)
for i in range(1, 45):
    print(f'{i}:{rv.cdf(i)}')
```

从结果上，需要保持39的库存时，有95%的概率不会出现缺货。



#### 几何分布与指数分布

几何分布是离散型概率密度，其中一种定义为：在n次贝努利试验中，试验k次才得到第一次成果的概率。

几何分布

```python
filps_till_heads = stats.geom.rvs(size=1000, p=0.5)
filps_till_heads
pd.DataFrame(filps_till_heads).hist(range=(-0.5, max(filps_till_heads)+0.5), bins=max(filps_till_heads)+1)
```

指数分布是描述泊松分布过程中的事件之间的事件的概率分布，即事件以恒定平均速率连续且独立地发生的过程。它是几何分布的连续模拟，具有无记忆的关键性质。

指数分布用来描述独立随机事件发生的时间间隔，以等公交车为例，两辆车到来的时间间隔就符合指数分布。假设公交车到达的时间服从参数lambda=6的指数分布，那么15分钟以内有公交车到达的概率为

```python
prob_1 = stats.expon.cdf(x=0.25, scale=1/6)  # scale=1/lambda
prob_1
```



## 点估计与置信区间

统计推断是分析样本数据以从中了解总体的过程。在数据分析中，经常对某些总体的特征感兴趣，但收集整个数据总体可能不可行。例如，经济普查中对收入的调查，对每个人进行调查并不可行。现实场景中的经济普查都是对一部分人进行普查，如抽样10000人，使用这些数据去推断总体。

### 点估计

点估计正是基于样本数据的总体参数估计方法。例如，如果想知道人群的平均年龄，那么可以对登记人群进行调查，然后使用他们的平均年龄的点估计作为总体的估计。这里的样本平均值作为样本平均值，样本平均值与总体平均不完全相同。这种差异由许多因素造成，包括调查设计不佳，抽样方法有偏见以及随机从总体中抽取样本所固有的误差。

例子：生成一个人群数据的总体，然后从中抽取样本以估算均值。

```python
# 构造总体
population_ages1 = stats.poisson.rvs(loc=18, mu=35, size=150000)  # loc为均值，mu为方差
population_ages2 = stats.poisson.rvs(loc=18, mu=10, size=100000)
population_ages = np.concatenate([population_ages1, population_ages2])
population_ages.mean()  # 总体均值 43.008308
# 抽样
sample_ages = np.random.choice(population_ages, size=500)
sample_ages.mean()
# 计算误差
abs(population_ages.mean()-sample_ages.mean())
```

### 抽样分布与中心极限定理

许多统计过程都假定数据遵循正态分布，因为正态分布具有良好的数学，如对称性，并且大多数数据都聚集在一个平均值标准偏差内。不幸的是，现实世界中的数据通常不是正态分布的。而样本的分布趋向于反映总体的分布，这意味着从具有偏斜分布的人群中获取的样本也将趋于偏斜。

以刚刚的年龄数据为例，将其可视化。

```python
pd.DataFrame(population_ages).hist(range=(17.5, 75.5), bins=58, figsize=(10, 6))
stats.skew(population_ages)  # 计算偏度
```

这里可以看出，该总体偏度虽然不大，但显然不是正态分布，而是有两个峰。抽样后可视化展示，也是两个峰。

显然，样本的分布形状与总体的分布形状大致相同。由此表面不能将假定正态分布应用于此数据集，因为从上面的图形看出该分布不是正态分布。

那么非正态分布的数据应该怎么进行参数估计呢？幸运的是，有数学家提出了中心极限定理。中心极限定理是概率论最重要的理论之一，它是许多统计分析方法的基础。简单来说，中心极限定理指的是给定一个任意分布的总体，每次从这些总体中随机抽取n个抽样，一共抽取m次，然后把这m组抽样分别求出平均值，最终得到的平均值的分布接近正态分布。

代码举例：

```python
point_estimates = []
for x in range(200):
    sample = np.random.choice(population_ages, size=5000)
    point_estimates.append(sample.mean())
pd.DataFrame(point_estimates).plot(kind='density', figsize=(10, 6), xlim=(41, 45))
```

这个图形就基本上符合正态分布了。



### 置信区间

点估计可以让我们大致了解总体参数（如均值），但估计是容易出错的，并且采取多个样本来获得改进的估计值可能并不可行。因此，统计学家又引入了置信区间，一个概率样本的置信区间是对这个样本的某个总体参数的区间估计。置信区间展现的是这个参数的真实值有一定的概率落在测量结果的周围的程度。置信区间给出的是被测量参数的测量值的可信程度，即前面所要求的的“一定概率”。这个概率被称为置信度或置信水平。如果想拥有一个95%的机会通过点估计或相应的方法来捕获真实的总体参数置信区间，那么可以将置信度设置为95%。较高的置信度会得到范围更广的置信区间。在已经得到点估计的情况下，将其加上和减去边际误差就可以得到置信区间。

```python
# 获取样本均值
sample = np.random.choice(population_ages, size=1000)
sample_mean = sample.mean()
# 获取分位数值
z_critical = stats.norm.ppf(q=0.975)  # 双尾
# 计算置信区间
pop_stdev = population_ages.std()  # 计算标准差
margin_of_error = z_critical * (pop_stdev/np.sqrt(1000))  # 计算平均标准误
confidence_interval = (sample_mean-margin_of_error, sample_mean+margin_of_error)
confidence_interval
```

