# 第十六章 一名数据分析师的游戏上线之旅

移动应用间的竞争越来越激烈，每天都有新的应用上线。你所在的公司也不例外，项目组经过5个月的紧张开发，终于完成了一款新的移动游戏应用，明天就准备上线了。作为一名数据分析师，你将遇到哪些问题呢？应用第一天上线后会不会因为大量用户涌入，导致应用启动时间比要求的3秒长？次日留存率是否达到目标？应该在游戏的哪一个关卡引入微信分析提示？游戏内购买价是1.99元还是0.99元更好？

## 游戏启动时间是否超过目标

管理团队为了随时了解公司的游戏软件上线情况，一开始就设计了一些简单的运营指标来跟踪游戏运营情况。其中一个指标就是：启动游戏后欢迎界面平均等待时间不能超过3秒。测试团队经过了大量测试，已经验证无论是在iOS还是Anroid平台，欢迎界面等待时间都不超过3秒。游戏上线后也一切运行正常，然而不妙的是上线6小时后，游戏的上一小时平均启动时间开始超过了管理层设定的3秒平均值。紧张的项目经理跑来问你——团队的数据分析师，这是否可能是用户过多导致启动延迟？

### 启动时间是否超过3秒

回答这个问题，首先要看一些模拟的游戏运营数据。

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns
import datetime
import warnings

warnings.filterwarnings('ignore')

colors = sns.color_palette()
# sns.set_style('whitegrid')
plt.style.use('fivethirtyeight')
plt.rcParams['font.sans-serif'] = 'SimHei'
plt.rcParams['axes.unicode_minus'] = False

%matplotlib inline
```

生成数据
```python
observation_hours = 7 # 假定游戏以及上线7小时
expected_installed = 60 # 预期每小时有60人安装
loading_times = []
loading_times_averages = []
np.random.seed(12)

for ix, installs in enumerate(np.random.poisson(lam=expected_installed,
                                                size=observation_hours)):
    loading_times.append(np.random.gamma(shape=3, scale=0.95, size=installs))
    loading_times_averages.append(loading_times[ix].mean())
    
"""
对代码进行一下解释:
	首先是生成迭代对象,其中生成的对象大小由游戏小时决定,即这里迭代7次
	然后installs值为每小时安装人数
	然后通过gamma分布,每个人生成一个均值3小时的数据,然后存入loading_times,然后调用ix求前几个的平均
"""
```

画图展示

```python
# 展示游戏启动时间
fix, ax = plt.subplots(figsize=(10, 3.4))
ax.plot(loading_times_averages, marker='o')
ax.plot([0, observation_hours-1], [3, 3], '--', color='black')  # 这条是水平线
ax.set(title='平均启动时间', xlabel='游戏已上线时间', ylabel='启动时间(秒)', ylim=(2.3, 3.5))
plt.show()
# 展示装机人数
fig, ax = plt.subplots(figsize=(10, 3.4))
plt.plot([len(x)for x in loading_times], marker='o')
plt.title('每小时装机数', fontsize=18)
plt.xlabel('游戏已上线时间')
plt.ylabel('装机数')
plt.show()
```

考察最后一小时的数据，对其启动时间进行可视化。

```python
fig, ax = plt.subplots(figsize=(10, 4))
plt.bar(range(loading_times[6].shape[0]), loading_times[6], align='center')
plt.plot([-1, 100], [3, 3], '--', color='0.3')
plt.xlim(-1, 61)
plt.title('过去一小时用户启动时间', fontsize=16)
plt.ylabel('秒')
plt.xticks([])
plt.show()
```

虽然确实有许多用户的启动时间在3s以上，但是管理层关心的问题是：过去一小时的问题是否具有普适性。作为项目经理，对这一异常感到紧张是很正常的事，然而作为一名数据分析师，对此提出的问题却应该是：最近一小时的平均启动时间是否来自平均启动时间不超过3s的启动时间分布？很显然，这是一个统计检验问题，那么该采用何种假设检验呢？

这里应该是采用t单样本均值检验：

+ $H_0$：前一小时总体的观察平均值小于或等于3秒。
+ $H_1$：前一小时总体的观察平均值大于3秒。
+ 检验：单样本，单尾t检验，$\alpha=0.05$

```python
from scipy import stats
t, p = stats.ttest_1samp(loading_times[6], popmean=3)
t, p
```

根据p值，我们可以知道我们无法拒绝原假设，此时，你要去拍一拍项目经理的肩膀，告诉他：“老大，目前的情况应该很正常，出现启动时间大于3秒应该是偶然事件。”

### 构造启动时间检测图

项目经理已经满意的离开了，但是如果每次出现启动时间大于3秒，他就很紧张地到你这里来确认是不是偶然事件，显然不是问题的解决之道。那应该如何来处理这一问题呢？

构建一个置信区间，当平均启动时间在置信区间之外，我们才应该特别关注。

```python
x = loading_times[6]
SE = stats.sem(x)  # 标准误 就是x/sqrt{n}
t_c = stats.t.ppf(0.975, df=len(x)-1)
CI = x.mean() - t_c*SE, x.mean() + t_c*SE
```

对每一个小时都做置信区间

```python
loading_performance = pd.DataFrame(loading_times_averages, columns=['loadingtime'])
loading_performance['installs'] = [len(x) for x in loading_times]  # 处理的是每一个小时
loading_performance['SE'] = [stats.sem(x) for x in loading_times]
loading_performance['t_critical'] = stats.t.ppf(0.975, df=loading_performance['installs']-1)
loading_performance['CI_low'] = loading_performance['loadingtime'] -\
                    loading_performance['t_critical']*loading_performance['SE']
loading_performance['CI_high'] = loading_performance['loadingtime'] +\
                    loading_performance['t_critical']*loading_performance['SE']

loading_performance
```

用区域填充图画图显示

```python
fig, ax = plt.subplots(figsize=(10, 3.4))
ax.plot(loading_times_averages, marker='o')
ax.plot([0, observation_hours-1], [3, 3], '--', color='0.3')
ax.fill_between(loading_performance.index, loading_performance['CI_low'],
                loading_performance['CI_high'], alpha=0.2,
               where=loading_performance['CI_low']<loading_performance['CI_high'])
# where的意思是,如果不满足就没有,不会出现倒着

ax.set(xlabel='游戏已上线时间', ylabel='启动时间(秒)', ylim=(2, 4), title='平均启动时间')
plt.show()


plt.subplots(figsize=(10, 2))
plt.plot(loading_performance['installs'], marker='o')
plt.ylim(0, loading_performance['installs'].max()*1.1)
plt.title('每小时装机数')
plt.xlabel('游戏已上线时间')
plt.ylabel('装机数')
plt.show()
```

然后将时间再扩充24小时

```python
observation_hours = 24
expected_installs = 60
np.random.seed(23)
loading_times2 = list(loading_times)
loading_times_average2 = list(loading_times_averages)

for ix, installs in enumerate(np.random.poisson(lam=expected_installs,
                                                size=observation_hours)):
    loading_times2.append(np.random.gamma(shape=3, scale=0.95, size=installs))
    loading_times_average2.append(loading_times2[ix].mean())
    
loading_performance = pd.DataFrame(loading_times_average2, columns=['loadingtime'])
loading_performance['installs'] = [len(x) for x in loading_times2]
loading_performance['SE'] = [stats.sem(x) for x in loading_times2]
loading_performance['t_critical'] = stats.t.ppf(0.975, df=loading_performance['installs']-1)
loading_performance['CI_low'] = loading_performance['loadingtime'] - \
                        loading_performance['t_critical']*loading_performance['SE']
loading_performance['CI_high'] = loading_performance['loadingtime'] + \
                        loading_performance['t_critical']*loading_performance['SE']
loading_performance.sample(3)


fig, ax = plt.subplots(figsize=(20, 3.4))
ax.plot(loading_times_average2, marker='o')
ax.plot([0, observation_hours+6], [3, 3], '--', color='0.3')
ax.fill_between(loading_performance.index, loading_performance['CI_low'],
                loading_performance['CI_high'], alpha=0.2,
               where=loading_performance['CI_low']<loading_performance['CI_high'])
# where的意思是,如果不满足就没有,不会出现倒着

ax.set(xlabel='游戏已上线时间', ylabel='启动时间(秒)', ylim=(2, 4), title='平均启动时间')
plt.show()
```



### 次日留存率是否大于30%

现在，游戏已经成功上线1天了，项目经理又开始计算次日留存率指标。

```python
installs = 448
returned = 123
p = returned / installs
print(f'装机数={installs}\n次日留存{returned}\n次日留存率={round(p*100, 2)}%\n目标留存率={30}%')
```

画图展示

```python
from matplotlib.ticker import FuncFormatter


fig, ax = plt.subplots(figsize=(8, 4))
ax.bar([1], [p], align='center', width=0.8)
ax.plot([0, 100], [0.3, 0.3], '--', color='0.3')
ax.set(xticks=range(1, 5), xlim=(0, 5), ylim=(0, 0.40), title='次日留存率')
ax.set_xticklabels(['{} Sep'.format(d+5) for d in range(1, 5)])
ax.text(1, p*0.95, '{:.2f}%'.format(p*100),
        horizontalalignment='center', verticalalignment='top',
        fontdict={'size':15, 'weight':'bold', 'color':(0.9, 0.9, 0.9)})
ax.yaxis.set_major_formatter(FuncFormatter(lambda x, pos: '{:.2f}%'.format(x*100)))
plt.show()
```

现在运营团队是否应该为第一天上线后的次日留存率小于30%而担心？很显然，这又是一个统计检验问题，只不过这次遇到的问题是单样本比例问题。

这里使用statsmodel库

```python
from statsmodels.stats.proportion import proportions_ztest, proportion_confint
# 作检验
z, p = proportions_ztest(returned, installs, value=0.3, alternative='smaller', prop_var=0.3)
"""
proportions_ztest(count，nobs，value = None，Alternative =‘two-side’，prop_var = False)
count:表示试验成功的次数
nobs:表示试验的数量
Alternative
"""
z, p
# 作置信区间
ci_low, ci_upp = proportion_confint(returned, installs)
ci_low, ci_upp
```

### 应该在游戏第几关加入关联微信提示

#### A/B测试

经过多日数据跟踪，启动时间和次日留存率等各项指标一切正常。现在项目经理打算着手解决游戏设计之初就激烈讨论的一个问题：应该在游戏第几关加入微信关联页面？在微信当道的今天，游戏产品经理希望用户尽可能地关联他们的微信帐号，这样运营团队就可以更好地了解用户以及他们的好友，因此，产品经理想对两种不同的微信登陆页面进行测试，一种是在游戏第一关时加入微信关联页面，另一种是在游戏第二关加入。需要说明的是，该游戏前三关难度都不大，根据运营团队估算，几乎90%以上用户都会通过前面3关，因此不会存在通过第一关和第二关的用户有很大差别的情况。为了对以上两种策略进行比较，项目组精心设计了以下试验：将用户随机分组，控制组2501人，测试组2141人，控制组在第一关弹出关联微信页面，测试组在第二关弹出关联微信页面。最终测试结果如下：

```python
# 随机生成数据
control_installs = 2501
control_connected = 1104
test_installs = 2141
test_connected = 1076
print(f'类别{"A"}:装机数:{control_installs}\t关联微信数:{control_connected}\t比例:{control_connected/control_installs}')
print(f'类别{"B"}:装机数:{test_installs}\t关联微信数:{test_connected}\t比例:{test_connected/test_installs}')
```

将结果进行可视化

```python
from matplotlib.ticker import FuncFormatter


fig, ax = plt.subplots(figsize=(8, 4))
x = [0, 1]
y = [control_connected/control_installs, test_connected/test_installs]
ax.bar(x, y, align='center', width=0.8)
ax.set_xticks(x)
ax.set_xticklabels(['控制', '测试'])
ax.set(xlim=(-.5, 1.5), ylim=(0, .69), title='哪种策略更好')
for xx, yy in zip(x, y):
    ax.text(xx, yy*0.7, f'{round(100*yy, 2)}%', ha='center', va='bottom',
           fontdict={'color':(0.8, 0.8, 0.8), 'weight':'bold'})
ax.yaxis.set_major_formatter(FuncFormatter(lambda x, pos:'{:.2f}%'.format(x*100)))
plt.show()
```

与前面的问题处理方式一样，根据描述，目前需要处理的是双样本，比例问题。

```python
from statsmodels.stats.proportion import proportions_ztest
count = np.array([control_connected, test_connected])
nobs = np.array([control_installs, test_installs])
z, p = proportions_ztest(count, nobs, value=0, alternative='two-sided')
z, p
```

这里可以看到，p值远小于0.05，那么应该拒绝原假设，即两种关联决策是有区别的。数据分析师应该告诉产品经理在第二关引入该页面有更好的效果。

不过产品经理不仅关心哪种策略更好，他还关心采用这一策略游戏的微信关联指标能提高多少，将其转化为统计语言实际就是策略二的关联比例减去策略一关联比例的置信区间。

要解决此问题，首先需要计算出标准误差和z值。

```python
def compute_standard_error_prop_two_samples(x1, n1, x2, n2, alpha=0.05):
    p1 = x1/n1
    p2 = x2/n2
    se = p1*(1-p1)/n1 + p2*(1-p2)/n2
    return np.sqrt(se)
    
    
def zconf_interval_two_samples(x1, n1, x2, n2, alpha=0.05):
    p1 = x1/n1
    p2 = x2/n2
    se = compute_standard_error_prop_two_samples(x1, n1, x2, n2, alpha=alpha)
    z_critical = stats.norm.ppf(1-0.5*alpha)
    return p2-p1-z_critical*se, p2-p1+z_critical*se
    
    
ci_low, ci_upp = zconf_interval_two_samples(control_connected, control_installs, test_connected, test_installs)
ci_low, ci_upp
```

在$\alpha=0.05$的情况下，置信区间为3.24%~8.99%。从统计学角度，就是说$(p_2-p_1)$有95%的可能落在这个区间，因此可以认为，第二种策略下，微信关联指标的提示在3.24%以上。



#### 贝叶斯解决方案

了解概率论的读者看到这里可能会说：“前面都是采用频率学派的解决办法。”如果用贝叶斯的解决方法该怎么做呢？其实可以用PyMC3这个包来完成。

（过于复杂这里略）





### 如何定价

目前游戏中用户在通关失败后可以花1.99元获得新的生命进行尝试。但是运营推广部门认为1.99元太贵了，这样大量玩家都不会成为付费用户。他们建议降价到0.99元，这样虽然价格低了，但是整体上游戏收入将提高。因此设计了如下的A/B测试：

+ 只对新用户进行测试；
+ 运行两个月；
+ 统计每个用户前30天的总收入；
+ 空假设：0.99元组收入更高；

具体度量指标：

+ 每用户平均收入值在前30天的区别；
+ 转化率（多少比例用户至少购买一次）。

生成数据

```python
conversion_a = 0.015
conversion_b = 0.013
installs_a = 30000
installs_b = 30000
payers_a = int(installs_a * conversion_a)
payers_b = int(installs_b * conversion_b)
print(f"A组付费用户数:{payers_a}")
print(f"B组付费用户数:{payers_b}")
```

统计检验

```python
from statsmodels.stats.proportion import proportions_ztest


count = np.array([payers_a, payers_b])
nobs = np.array([installs_a, installs_b])
z, p = proportions_ztest(count, nobs, value=0, alternative='two-sided')
z, p
```

由于p值=0.037，因此认为具有统计显著性。确实0.99元的效果比1.99元要好。



ARPU数据（ARPU就是每用户平均收入）， 生成模拟数据

```python
np.random.seed(8)
revenues_a = np.clip(np.random.gamma(0.7, 10, payers_a).astype(np.int), 1, 1000) *\
            np.clip(np.random.gamma(1, 25, payers_a).round(2), 0.99, 99)
# np.clip就是把值限定到一个范围,如果超出范围,就用范围的两边代替
revenues_b = np.clip(np.random.gamma(0.7, 13, payers_b).astype(np.int), 1, 1000) * \
            np.clip(np.random.gamma(1, 30, payers_b).round(2), 2.99, 99)
print(f'A:ARPU={revenues_a.mean()},min={revenues_a.min()},max={revenues_a.max()}')
print(f'B:ARPU={revenues_b.mean()},min={revenues_b.min()},max={revenues_b.max()}')

# 对其进行描述性统计
pd.set_option('display.precision', 2)
pd.DataFrame(data=revenues_a, columns=['0.99']).describe().join(pd.DataFrame(data=revenues_b, columns=['1.99']).describe())
```

数据可视化

```python
x = [0, 1]
y = [revenues_a.mean(), revenues_b.mean()]

fig, ax = plt.subplots(figsize=(8, 4))
ax.bar(x, y, align='center', width=.8)
ax.set_xticks(x)
ax.set_xticklabels(['0.99元', '1.99元'])
ax.set_title('付费用户 ARPU')
ax.set_xlim(-.5, 1.5)
for xx, yy in zip(x, y):
    ax.text(xx, yy*0.7, '{:.2f}%'.format(yy), color=(.9, .9, .9))
    
ax.yaxis.set_major_formatter(FuncFormatter(lambda x, pos: '{:.2f}%'.format(x)))
plt.show()
```

从ARPU角度来看，1.99元组具有更高的付费用户ARPU。

现在将所有用户考虑进来计算ARPU

```python
# 没有付钱的即为0
revenues_a = np.concatenate([np.zeros(installs_a - payers_a), revenues_a])
revenues_b = np.concatenate([np.zeros(installs_b - payers_b), revenues_b])

print('A:ARPU={}, min={}, max={}'.format(revenues_a.mean(), revenues_a.min(), revenues_a.max()))
print('B:ARPU={}, min={}, max={}'.format(revenues_b.mean(), revenues_b.min(), revenues_b.max()))

t, p = stats.ttest_ind(revenues_a, revenues_b, axis=0, equal_var=False)
t, p/2
```

这里看到p值为0.09， 无法拒绝原假设，因此我们认为，1.99元组消费更高只是偶然因素，游戏应该对所有降价？从统计学角度回答很简单，但是如果从商业角度也许就变得更复杂。如果查看模拟的数据，可以发现有少数用户消费在1000元以上，这些就是所谓的VIP游戏玩家了，如果将这一部分用户去掉后进行观察，将得到如下结果。

```python
revenues_a_trimmed = np.minimum(revenues_a, 1000)  # 返回两个中小的那一个
revenues_b_trimmed = np.minimum(revenues_b, 1000)
print('A:ARPU={}'.format(revenues_a_trimmed.mean()))
print('B:ARPU={}'.format(revenues_b_trimmed.mean()))
```

重新计算p值

```python
t, p = stats.ttest_ind(revenues_a_trimmed, revenues_b_trimmed, axis=0, equal_var=False)
t, p/2
```

此时，p=0.037，是否意味着应该拒绝原假设？其实仅凭这些数据，我们是无法知道定价是如何影响这些客户的，不过商业决策是有风险的，也许更好的方式是继续采用1.99元的定价，之后用更激进的定价策略，进行新一轮的A/B测试。

